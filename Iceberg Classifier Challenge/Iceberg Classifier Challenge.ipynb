{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iceberg Classifier Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the json data using pandas and replace all the \"na\" values of incident angle with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_json(\"train.json\")\n",
    "train_data.inc_angle = train_data.inc_angle.replace(\"na\",39.26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the raw data into numpy arrays for traininig and resize them to 150*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_data[\"band_1\"]])\n",
    "band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_data[\"band_2\"]])\n",
    "train = np.concatenate([band1[:, :, :, np.newaxis]\n",
    "                          , band2[:, :, :, np.newaxis]\n",
    "                         , ((band1+band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "#train = np.array([scipy.misc.imresize(x,(150,150)) for x in train])\n",
    "angle_train = np.array(train_data.inc_angle)\n",
    "train_labels = np.array(train_data[\"is_iceberg\"])\n",
    "\n",
    "# Split data in two for validation and traininig\n",
    "train, valid, angle_train, angle_valid, train_label, valid_label = train_test_split(train\n",
    "                    , angle_train, train_labels, random_state=25, train_size=0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, Concatenate, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "gen=ImageDataGenerator(rotation_range=360, \n",
    "                       horizontal_flip=True, \n",
    "                       vertical_flip=True, \n",
    "                       shear_range=0.2, \n",
    "                       zoom_range=0.2,\n",
    "                       width_shift_range=0.2,\n",
    "                       height_shift_range=0.2)\n",
    "batch_size = 64\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=121)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=121)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "gen_flow = gen_flow_for_two_inputs(train, angle_train, train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Inception-ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "input1 = Input(shape=(150, 150, 3))\n",
    "base_model = InceptionResNetV2(include_top=True, \n",
    "                               weights='imagenet', \n",
    "                               input_tensor=input1, \n",
    "                               input_shape=(150, 150, 3), \n",
    "                               classes=1000)\n",
    "\n",
    "x = base_model.output\n",
    "input2 = Input(shape=(1,))\n",
    "#x = (Concatenate()([x, BatchNormalization(momentum=0)(input2)]))\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1000, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=[input1,input2], outputs=predictions)\n",
    "\n",
    "#first: train only the top layers\n",
    "for layer in base_model.layers[:len(base_model.layers)-20]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "input1 = Input(shape=(75, 75, 3))\n",
    "b1 = BatchNormalization(momentum=0)(input1)\n",
    "x = Conv2D(64, (5,5), padding='same')(b1)\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(128, (5,5), padding='same')(x)\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(256, (5,5), padding='same')(x)\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(256, (3,3), padding='same')(x)\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(512, (3,3), padding='same')(x)\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "input2 = Input(shape=(1,))\n",
    "#x = Concatenate()([x,input2])\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1000)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[input1,input2], outputs=predictions)\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(gen_flow, validation_data=([valid, angle_valid], valid_label),\n",
    "                    steps_per_epoch=len(train) / batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"m.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_json(\"test.json\")\n",
    "# Test data\n",
    "test_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\"band_1\"]])\n",
    "test_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\"band_2\"]])\n",
    "test = np.concatenate([test_band1[:, :, :, np.newaxis]\n",
    "                          , test_band2[:, :, :, np.newaxis]\n",
    "                         , ((test_band1+test_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "test = np.array([scipy.misc.imresize(x,(150,150)) for x in test])\n",
    "angle_test = np.array(test_data.inc_angle)\n",
    "\n",
    "predictions = model.predict([test,angle_test])\n",
    "\n",
    "df = test_data[['id']].copy()\n",
    "df['is_iceberg'] = predictions\n",
    "df.to_csv('predictions3.csv', index = False)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
