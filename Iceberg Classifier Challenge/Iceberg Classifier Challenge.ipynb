{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iceberg Classifier Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the json data using pandas and replace all the \"na\" values of incident angle with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n",
      "1604\n",
      "1604\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_json(\"train.json\")\n",
    "print(len(train_data.inc_angle))\n",
    "train_data.inc_angle = train_data.inc_angle.replace(\"na\",39.26)\n",
    "print(len(train_data.inc_angle))\n",
    "train_data.inc_angle = train_data.inc_angle.astype(float).fillna(39.26)\n",
    "print(len(train_data.inc_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_data.inc_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the raw data into numpy arrays for traininig and resize them to 150*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Sai\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43.9239  38.1562  45.2859 ...,  39.26    39.26    39.26  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_data[\"band_1\"]])\n",
    "band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_data[\"band_2\"]])\n",
    "train = np.concatenate([band1[:, :, :, np.newaxis]\n",
    "                          , band2[:, :, :, np.newaxis]\n",
    "                         , ((band1+band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "train = np.array([scipy.misc.imresize(x,(150,150)) for x in train])\n",
    "angle_train = np.array(train_data.inc_angle)\n",
    "print(angle_train)\n",
    "train_labels = np.array(train_data[\"is_iceberg\"])\n",
    "\n",
    "# Split data in two for validation and traininig\n",
    "train, valid, angle_train, angle_valid, train_label, valid_label = train_test_split(train\n",
    "                    , angle_train, train_labels, random_state=25, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(angle_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, concatenate, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen=ImageDataGenerator(rotation_range=360, \n",
    "                       horizontal_flip=True, \n",
    "                       vertical_flip=True, \n",
    "                       shear_range=0.2, \n",
    "                       zoom_range=0.2,\n",
    "                       width_shift_range=0.2,\n",
    "                       height_shift_range=0.2)\n",
    "batch_size = 32\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=121)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=121)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "gen_flow = gen_flow_for_two_inputs(train, angle_train, train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input1 = Input(shape=(150, 150, 3))\n",
    "base_model = InceptionResNetV2(include_top=True, \n",
    "                               weights='imagenet', \n",
    "                               input_tensor=input1, \n",
    "                               input_shape=(150, 150, 3), \n",
    "                               classes=1000)\n",
    "\n",
    "x = base_model.output\n",
    "input2 = Input(shape=(1,))\n",
    "#x = (Concatenate()([x, BatchNormalization(momentum=0)(input2)]))\n",
    "x = BatchNormalization(momentum=0)(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1000, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=[input1,input2], outputs=predictions)\n",
    "\n",
    "#first: train only the top layers\n",
    "for layer in base_model.layers[:len(base_model.layers)-20]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38/37 [==============================] - 383s 10s/step - loss: 0.3459 - acc: 0.8382 - val_loss: 0.3181 - val_acc: 0.8678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x397acdd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen_flow, validation_data=([valid, angle_valid], valid_label),\n",
    "                    steps_per_epoch=len(train) / batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"m3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test.json\")\n",
    "# Test data\n",
    "test_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\"band_1\"]])\n",
    "test_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\"band_2\"]])\n",
    "test = np.concatenate([test_band1[:, :, :, np.newaxis]\n",
    "                          , test_band2[:, :, :, np.newaxis]\n",
    "                         , ((test_band1+test_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "test = np.array([scipy.misc.imresize(x,(150,150)) for x in test])\n",
    "angle_test = np.array(test_data.inc_angle)\n",
    "\n",
    "predictions = model.predict([test,angle_test])\n",
    "\n",
    "df = test_data[['id']].copy()\n",
    "df['is_iceberg'] = predictions[:,1]\n",
    "df.to_csv('predictions2.csv', index = False)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = test_data[['id']].copy()\n",
    "df['is_iceberg'] = predictions[:,1]\n",
    "df.to_csv('predictions.csv', index = False)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
